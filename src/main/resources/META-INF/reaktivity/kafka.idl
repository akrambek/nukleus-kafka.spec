/*
 * Copyright 2016-2019 The Reaktivity Project
 *
 * The Reaktivity Project licenses this file to you under the Apache License,
 * version 2.0 (the "License"); you may not use this file except in compliance
 * with the License. You may obtain a copy of the License at:
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
 * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
 * License for the specific language governing permissions and limitations
 * under the License.
 */
scope kafka
{
    struct KafkaConfig
    {
        string16 name;
        string16 value;
    }

    struct KafkaPartition
    {
        int32 partitionId;
        int32 leaderId;
    }

    struct KafkaOffset
    {
        int32 partitionId;
        int64 offset;
    }

    enum KafkaConditionType (uint8)
    {
        KEY (0),
        HEADER (1)
    }

    union KafkaCondition switch (uint8)
    {
        case 0: kafka::KafkaKey key;
        case 1: kafka::KafkaHeader header;
    }

    struct KafkaFilter
    {
        KafkaCondition[] conditions; // ANDed
    }

    struct KafkaKey
    {
        int32 length;
        octets[length] value = null;
    }

    struct KafkaHeader
    {
        string16 name;
        int32 valueLen;
        octets[valueLen] value = null;
    }

    scope control
    {
        struct KafkaRouteEx
        {
            string16 topic; // TODO: wildcard
        }
    }

    scope stream
    {
        enum KafkaApi (uint8)
        {
            META (3),
            DESCRIBE (32),
            FETCH (1),
            PRODUCE (0)
        }

        union KafkaBeginEx switch (uint8) extends core::stream::Extension
        {
            case 3: kafka::stream::KafkaMetaBeginEx meta;
            case 32: kafka::stream::KafkaDescribeBeginEx describe;
            case 1: kafka::stream::KafkaFetchBeginEx fetch;
            case 0: kafka::stream::KafkaProduceBeginEx produce;
        }

        union KafkaDataEx switch (uint8) extends core::stream::Extension
        {
            case 3: kafka::stream::KafkaMetaDataEx meta;
            case 32: kafka::stream::KafkaDescribeDataEx describe;
            case 1: kafka::stream::KafkaFetchDataEx fetch;
            case 0: kafka::stream::KafkaProduceDataEx produce;
        }

        union KafkaEndEx switch (uint8) extends core::stream::Extension
        {
            case 3: kafka::stream::KafkaMetaEndEx meta;
            case 32: kafka::stream::KafkaDescribeEndEx describe;
            case 1: kafka::stream::KafkaFetchEndEx fetch;
            case 0: kafka::stream::KafkaProduceEndEx produce;
        }

        struct KafkaResetEx extends core::stream::Extension
        {
            uint16 error = 0;
        }

        struct KafkaMetaBeginEx
        {
            string16 topic;
        }

        struct KafkaMetaDataEx
        {
            KafkaPartition[] partitions;
        }

        struct KafkaMetaEndEx
        {
        }

        struct KafkaDescribeBeginEx
        {
            string16 topic;
            string16[] configs;
        }

        struct KafkaDescribeDataEx
        {
            KafkaConfig[] configs;
        }

        struct KafkaDescribeEndEx
        {
        }

        struct KafkaFetchBeginEx
        {
            string16 topic;
            KafkaOffset[] progress; // partitionId = -1 applies offset to all unspecified partitionIds
            KafkaFilter[] filters; // ORed
        }

        struct KafkaFetchDataEx
        {
            int64 timestamp = 0;        // INIT only
            KafkaKey key;               // INIT only
            KafkaHeader[] headers;      // FIN only
            KafkaOffset[] progress;     // FIN only
        }

        struct KafkaFetchEndEx
        {
            KafkaOffset[] progress;
        }

        struct KafkaProduceBeginEx
        {
            string transaction; // = null;
            int64 producerId = 0;
            string16 topic;
        }

        struct KafkaProduceDataEx
        {
            KafkaKey key;
            KafkaHeader[] headers;
            KafkaOffset progress;  // partitionId == -1  implies hash(key) â‡’ partition, offset = seqno
        }

        struct KafkaProduceEndEx
        {
        }
    }
}
