#
# Copyright 2016-2019 The Reaktivity Project
#
# The Reaktivity Project licenses this file to you under the Apache License,
# version 2.0 (the "License"); you may not use this file except in compliance
# with the License. You may obtain a copy of the License at:
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
#

property newTimestamp ${kafka:timestamp()}

property networkAccept "nukleus://streams/kafka#0"
property networkAcceptWindow 8192

accept ${networkAccept}
  option nukleus:window ${networkAcceptWindow}
  option nukleus:transmission "duplex"
  option nukleus:byteorder "network"

# Metadata connection
accepted
connected

read 21         # Size int32
read 3s      # ApiKey int16 (Metadata)
read 5s      # ApiVersion int16
read (int:metadataRequestId)
read -1s        # ClientId string (null)
read 1          # [TopicName] array length
  read 4s "test"
read [0x00]     # allow_auto_topic_creation (boolean)

write 85        # Size int32
write ${metadataRequestId}  # CorrelationId int32
write 0         # throttle_time_ms int32
write 1         # brokers array length
  write 1       # broker id
  write 7s "broker1"
  write 9093    # port int32
  write -1s     # rack string (null)
write 9s "cluster 1"
write 1         # controller broker id
write 1         # topic array length
  write 0s      # error code
  write 4s "test"
  write byte 0           # is_internal
  write 1       # partition array length
    write 0s    # error code
    write 0     # partition
    write 1     # leader
    write 0     # replicas array (empty)
    write -1    # isr array (null)
    write 0     # offline replicas array (empty)

read 62         # Size int32
read 32s        # ApiKey int16 (DescribeConfigs)
read 0s         # ApiVersion int16
read (int:metadataRequestId) # CorrelationId int32
read -1s        # ClientId string (null)
read 1          # [Resources] array length
read [0x02]     # resource type int8 (topic) 
read 4s "test"  # topic name
read 2          # config_names count
read 14s "cleanup.policy"
read 19s "delete.retention.ms"

write 88        # Size int32
write ${metadataRequestId}  # CorrelationId int32
write 0         # throttle_time_ms int32
write 1         # resources count
write 0s        # error code
write -1s       # error message
write [0x02]    # resource type
write 4s "test" # topic name
write 2         # config entries count
write 14s "cleanup.policy"  # config name
write 6s "delete"           # config  value
write [0x00]    # read_only boolean
write [0x01]    # is_default boolean
write [0x00]    # is_sensitive boolean
write 19s "delete.retention.ms"
write 8s "86400000"
write [0x00]    # read_only boolean
write [0x01]    # is_default boolean
write [0x00]    # is_sensitive boolean

write await SHUTDOWN_BROKER
write close
read closed
read notify METADATA_CONNECTION_CLOSED


# Fetch connection
accepted
read nukleus:begin.ext ${tcp:beginExtRemoteHost("broker1", 9093)}
connected

# First fetch request
read 65
read 1s
read 5s
read (int:requestId)
read -1s
read -1
read [0..4]
read 1
read [0..4]
read [0x00]
read 1
read 4s "test"
read 1
read 0
read 0L         # offset
read -1L
read [0..4]

write 140
write ${requestId}
write 0
write 1
write 4s "test"
write 1         # partition count
write 0         # partition id
write 0s
write 1L        # high water mark
write -1L       # last stable offset
write 0L        # log start offset
write -1        # aborted transaction count
write 80        # record batch size
write 0L        # first offset
write 68        # record batch length
write 0         # leader epoque
write [0x02]    # magic
write 0x4e8723aa         # crc 
write 0s        # attributes
write 0         # last offset delta
write ${newTimestamp}    # first timestamp
write ${newTimestamp}    # max timestamp
write -1L                # producer ID
write -1s                # producer epoch
write -1                 # first sequence          
write 1                  # record count

write ${kafka:varint(18)}
write [0x00]    # attributes
write ${kafka:varint(0)}     # timestamp delta
write ${kafka:varint(0)}     # offset delta
write ${kafka:varint(-1)}
write ${kafka:varint(12)}
write "Hello, world"
write [0x00]

read 65
read 1s
read 5s
read (int:requestId)
read -1s
read -1
read [0..4]
read 1
read [0..4]
read [0x00]
read 1
read 4s "test"
read 1
read 0
read 1L         # offset
read -1L
read [0..4]

write await SHUTDOWN_BROKER
write await METADATA_CONNECTION_CLOSED
write close
read closed
read notify FETCH_CONNECTION_CLOSED

#  Historical connection
accepted
read nukleus:begin.ext ${tcp:beginExtRemoteHost("broker1", 9093)}
connected

write await SHUTDOWN_BROKER
write await FETCH_CONNECTION_CLOSED
write close
read closed

# Live connection fails to reconnect
accepted
read nukleus:begin.ext ${tcp:beginExtRemoteHost("broker1", 9093)}
connected

read 65
read 1s
read 5s
read (int:requestId)
read -1s
read -1
read [0..4]
read 1
read [0..4]
read [0x00]
read 1
read 4s "test"
read 1
read 0
read 1L         # offset
read -1L
read [0..4]

read abort
write aborted

write notify FETCH_CONNECTION_FAILED

# Historical connection fails to reconnect
accepted
read nukleus:begin.ext ${tcp:beginExtRemoteHost("broker1", 9093)}
connected

read abort
write aborted

# Metadata connection reconnects
accepted
connected

# Impacted metadata is refreshed, a broker node hostname has changed
read 21         # Size int32
read 3s      # ApiKey int16 (Metadata)
read 5s      # ApiVersion int16
read (int:metadataRequestId)
read -1s        # ClientId string (null)
read 1          # [TopicName] array length
  read 4s "test"
read [0x00]     # allow_auto_topic_creation (boolean)

write 88        # Size int32
write ${metadataRequestId}  # CorrelationId int32
write 0         # throttle_time_ms int32
write 1         # brokers array length
  write 1       # broker id
  write 10s "broker1new"
  write 9093    # port int32
  write -1s     # rack string (null)
write 9s "cluster 1"
write 1         # controller broker id
write 1         # topic array length
  write 0s      # error code
  write 4s "test"
  write byte 0           # is_internal
  write 1       # partition array length
    write 0s    # error code
    write 0     # partition
    write 1     # leader
    write 0     # replicas array (empty)
    write -1    # isr array (null)
    write 0     # offline replicas array (empty)

read 62         # Size int32
read 32s        # ApiKey int16 (DescribeConfigs)
read 0s         # ApiVersion int16
read (int:metadataRequestId) # CorrelationId int32
read -1s        # ClientId string (null)
read 1          # [Resources] array length
read [0x02]     # resource type int8 (topic) 
read 4s "test"  # topic name
read 2          # config_names count
read 14s "cleanup.policy"
read 19s "delete.retention.ms"

write 88        # Size int32
write ${metadataRequestId}  # CorrelationId int32
write 0         # throttle_time_ms int32
write 1         # resources count
write 0s        # error code
write -1s       # error message
write [0x02]    # resource type
write 4s "test" # topic name
write 2         # config entries count
write 14s "cleanup.policy"  # config name
write 6s "delete"           # config  value
write [0x00]    # read_only boolean
write [0x01]    # is_default boolean
write [0x00]    # is_sensitive boolean
write 19s "delete.retention.ms"
write 8s "86400000"
write [0x00]    # read_only boolean
write [0x01]    # is_default boolean
write [0x00]    # is_sensitive boolean

# Metadata is queried again when client re-attaches at offset 0
read 21         # Size int32
read 3s      # ApiKey int16 (Metadata)
read 5s      # ApiVersion int16
read (int:metadataRequestId)
read -1s        # ClientId string (null)
read 1          # [TopicName] array length
  read 4s "test"
read [0x00]     # allow_auto_topic_creation (boolean)

write 88        # Size int32
write ${metadataRequestId}  # CorrelationId int32
write 0         # throttle_time_ms int32
write 1         # brokers array length
  write 1       # broker id
  write 10s "broker1new"
  write 9093    # port int32
  write -1s     # rack string (null)
write 9s "cluster 1"
write 1         # controller broker id
write 1         # topic array length
  write 0s      # error code
  write 4s "test"
  write byte 0           # is_internal
  write 1       # partition array length
    write 0s    # error code
    write 0     # partition
    write 1     # leader
    write 0     # replicas array (empty)
    write -1    # isr array (null)
    write 0     # offline replicas array (empty)

read 62         # Size int32
read 32s        # ApiKey int16 (DescribeConfigs)
read 0s         # ApiVersion int16
read (int:metadataRequestId) # CorrelationId int32
read -1s        # ClientId string (null)
read 1          # [Resources] array length
read [0x02]     # resource type int8 (topic) 
read 4s "test"  # topic name
read 2          # config_names count
read 14s "cleanup.policy"
read 19s "delete.retention.ms"

write 88        # Size int32
write ${metadataRequestId}  # CorrelationId int32
write 0         # throttle_time_ms int32
write 1         # resources count
write 0s        # error code
write -1s       # error message
write [0x02]    # resource type
write 4s "test" # topic name
write 2         # config entries count
write 14s "cleanup.policy"  # config name
write 6s "delete"           # config  value
write [0x00]    # read_only boolean
write [0x01]    # is_default boolean
write [0x00]    # is_sensitive boolean
write 19s "delete.retention.ms"
write 8s "86400000"
write [0x00]    # read_only boolean
write [0x01]    # is_default boolean
write [0x00]    # is_sensitive boolean

# Live connection reconnects again, this time succeeds
accepted
read nukleus:begin.ext ${tcp:beginExtRemoteHost("broker1new", 9093)}
connected

# Second fetch request repeated, gets error because topic was recreated so offset 1 does not exist
read 65
read 1s
read 5s
read (int:requestId)
read -1s
read -1
read [0..4]
read 1
read [0..4]
read [0x00]
read 1
read 4s "test"
read 1
read 0
read 1L         # offset
read -1L
read [0..4]

write 60
write ${requestId}
write 0
write 1
write 4s "test"
write 1         # partition count
write 0         # partition
write 1s        # error code 1 (offset too early)
write -1L       # high watermark
write -1L       # last stable offset
write -1L       # log start offset
write -1        # aborted transaction count
write 0         # length of record batch

# List offsets request
read 41         # Size int32
read 2s         # ApiKey (ListOffsets)
read 2s         # ApiVersion 
read (int:listOffsetsRequestId) # CorrelationId 
read -1s        # ClientId string (null)
read -1         # replicaId
read [0x00]     # isolation level (0=READ_UNCOMMITTED)
read 1          # topic count 
read 4s "test"  # topic name
read 1          # partition count
read 0          # partition
read -2L        # timestamp (earliest available offset)

write 44        # Size int32
write ${listOffsetsRequestId}  # CorrelationId int32
write 0         # throttle_time_ms int32
write 1         # topic count
write 4s "test" # topic name 
write 1         # partition count
write 0         # partition
write 0s        # error code
write -1L       # timestamp (from a real example)
write 0L        # offset (zero because topic was recreated)

# Second fetch request is repeated at offset 0
read 65
read 1s
read 5s
read (int:requestId)
read -1s
read -1
read [0..4]
read 1
read [0..4]
read [0x00]
read 1
read 4s "test"
read 1
read 0
read 0L         # offset
read -1L
read [0..4]

write 140
write ${requestId}
write 0
write 1
write 4s "test"
write 1         # partition count
write 0         # partition id
write 0s
write 999L      # high water mark
write -1L       # last stable offset
write 0L        # log start offset
write -1        # aborted transaction count
write 80        # record batch size
write 0L        # first offset
write 68        # record batch length
write 0         # leader epoque
write [0x02]    # magic
write 0x4e8723aa         # crc 
write 0s        # attributes
write 0         # last offset delta
write ${newTimestamp}    # first timestamp
write ${newTimestamp}    # max timestamp
write -1L                # producer ID
write -1s                # producer epoch
write -1                 # first sequence          
write 1                  # record count

write ${kafka:varint(18)}
write [0x00]
write ${kafka:varint(10)}    # timestamp delta
write ${kafka:varint(0)}     # offset delta
write ${kafka:varint(-1)}
write ${kafka:varint(12)}
write "Hello, again"
write [0x00]
