#
# Copyright 2016-2018 The Reaktivity Project
#
# The Reaktivity Project licenses this file to you under the Apache License,
# version 2.0 (the "License"); you may not use this file except in compliance
# with the License. You may obtain a copy of the License at:
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
#

property networkConnect "nukleus://streams/kafka#0"
property networkConnectWindow 8192

property newMetadataRequestId ${kafka:newRequestId()}
property newRequestId1 ${kafka:newRequestId()}
property newRequestId2 ${kafka:newRequestId()}
property maximumWaitTime 500
property maximumBytes 65535
property maximumBytesTest0 8192

# Metadata connection
connect await ROUTED_SERVER
        ${networkConnect}
  option nukleus:window ${networkConnectWindow}
  option nukleus:transmission "duplex"
  option nukleus:byteorder "network"
connected

write 21        # Size int32
write 3s        # ApiKey int16 (Metadata)
write 5s        # ApiVersion int16
write ${newMetadataRequestId} # CorrelationId int32
write -1s       # ClientId string (null)
write 1         # [TopicName] array length
  write 4s "test"
write [0x00]    # allow_auto_topic_creation (boolean)

read 85         # Size int32
read ${newMetadataRequestId} # CorrelationId int32
read [0..4]     # throttle_time_ms int32
read 1          # brokers array length
  read 1        # broker id
  read 7s "broker1"
  read 9093     # port int32
  read -1s      # rack string (null)
read 9s "cluster 1"
read 1          # controller broker id
read 1          # topic array length
  read 0s       # error code
  read 4s "test"
  read [0x00]   # is_internal boolean
  read 1        # partition array length
    read 0s     # error code
    read 0      # partition
    read 1      # leader
    read 0      # replicas array (empty)
    read -1     # isr array (null)
    read 0      # offline replicas array (empty)

write 62        # Size int32
write 32s       # ApiKey int16 (DescribeConfigs)
write 0s        # ApiVersion int16
write ${newMetadataRequestId} # CorrelationId int32
write -1s       # ClientId string (null)
write 1         # resources count
write [0x02]    # resource type (topic is 2, from org/apache/kafka/common/resource/ResourceType.java)
write 4s "test" # topic name
write 2         # config names count
write 14s "cleanup.policy"  # config name
write 19s "delete.retention.ms" # config name

read 88         # Size int32
read ${newMetadataRequestId} # CorrelationId int32
read [0..4]     # throttle_time_ms int32
read 1          # resources count
read 0s         # error code
read -1s        # error message
read [0x02]     # resource type (topic)
read 4s "test"  # topic name
read 2          # config entries count
read 14s "cleanup.policy"   # config name
read 6s "delete"            # config value
read [0x00]     # read_only boolean
read [0x01]     # is_default boolean
read [0x00]     # is_sensitive boolean
read 19s "delete.retention.ms"
read 8s "86400000"
read [0x00]     # read_only boolean
read [0x01]     # is_default boolean
read [0x00]     # is_sensitive boolean

read notify METADATA_RECEIVED

# metadata is refreshed because of fetch error, now there are two partitions
write 21        # Size int32
write 3s        # ApiKey int16 (Metadata)
write 5s        # ApiVersion int16
write ${newMetadataRequestId} # CorrelationId int32
write -1s       # ClientId string (null)
write 1         # [TopicName] array length
  write 4s "test"
write [0x00]    # allow_auto_topic_creation (boolean)

read 129        # Size
read ${newMetadataRequestId} # CorrelationId int32
read [0..4]     # throttle_time_ms int32
read 2          # brokers array length
  read 1        # broker id
  read 7s "broker1"
  read 9093     # port int32
  read -1s      # rack string (null)

  read 2
  read 10s "broker2new"
  read 9093
  read -1s
read 9s "cluster 1"
read 1          # controller broker id
read 1          # topic array length
  read 0s       # error code
  read 4s "test"
  read [0x00]   # is_internal boolean
  read 2        # partition array length
    read 0s     # error code
    read 0      # partition
    read 1      # leader
    read 0      # replicas array (empty)
    read -1     # isr array (null)
    read 0      # offline replicas array (empty)

    read 0s     # error code
    read 1      # partition
    read 2      # leader
    read 0      # replicas array (empty)
    read -1     # isr array (null)
    read 0      # offline replicas array (empty)

# No describeConfigs call because partition count changed

# Impacted metadata is queried again because client was detached and resubscribes
write 21        # Size int32
write 3s        # ApiKey int16 (Metadata)
write 5s        # ApiVersion int16
write ${newMetadataRequestId} # CorrelationId int32
write -1s       # ClientId string (null)
write 1         # [TopicName] array length
  write 4s "test"
write [0x00]    # allow_auto_topic_creation (boolean)

read 129        # Size
read ${newMetadataRequestId} # CorrelationId int32
read [0..4]     # throttle_time_ms int32
read 2          # brokers array length
  read 1        # broker id
  read 7s "broker1"
  read 9093     # port int32
  read -1s      # rack string (null)

  read 2
  read 10s "broker2new"
  read 9093
  read -1s
read 9s "cluster 1"
read 1          # controller broker id
read 1          # topic array length
  read 0s       # error code
  read 4s "test"
  read [0x00]   # is_internal boolean
  read 2        # partition array length
    read 0s     # error code
    read 0      # partition
    read 1      # leader
    read 0      # replicas array (empty)
    read -1     # isr array (null)
    read 0      # offline replicas array (empty)

    read 0s     # error code
    read 1      # partition
    read 2      # leader
    read 0      # replicas array (empty)
    read -1     # isr array (null)
    read 0      # offline replicas array (empty)

write 62        # Size int32
write 32s       # ApiKey int16 (DescribeConfigs)
write 0s        # ApiVersion int16
write ${newMetadataRequestId} # CorrelationId int32
write -1s       # ClientId string (null)
write 1         # resources count
write [0x02]    # resource type (topic is 2, from org/apache/kafka/common/resource/ResourceType.java)
write 4s "test" # topic name
write 2         # config names count
write 14s "cleanup.policy"  # config name
write 19s "delete.retention.ms" # config name

read 88         # Size int32
read ${newMetadataRequestId} # CorrelationId int32
read [0..4]     # throttle_time_ms int32
read 1          # resources count
read 0s         # error code
read -1s        # error message
read [0x02]     # resource type (topic)
read 4s "test"  # topic name
read 2          # config entries count
read 14s "cleanup.policy"   # config name
read 6s "delete"            # config value
read [0x00]     # read_only boolean
read [0x01]     # is_default boolean
read [0x00]     # is_sensitive boolean
read 19s "delete.retention.ms"
read 8s "86400000"
read [0x00]     # read_only boolean
read [0x01]     # is_default boolean
read [0x00]     # is_sensitive boolean


# Fetch stream 1
connect await METADATA_RECEIVED
        ${networkConnect}
  option nukleus:window ${networkConnectWindow}
  option nukleus:transmission "duplex"
  option nukleus:byteorder "network"

write nukleus:begin.ext ${tcp:beginExtRemoteHost("broker1", 9093)}

connected

read notify FETCH_CONNECTION_ONE_CONNECTED

# Fetch connection 1
write 65
write 1s
write 5s
write ${newRequestId1}
write -1s
write -1
write ${maximumWaitTime}
write 1
write ${maximumBytes}
write [0x00]
write 1
write 4s "test"
write 1
write 0         # Partition
write 0L
write -1L
write ${maximumBytesTest0}

read 140
read ${newRequestId1}
read [0..4]
read 1          # Number of topic responses
read 4s "test"
read 1          # Number of partition responses
read 0          # Partition
read 0s
read 1L         # high watermark
read -1L
read 0L
read -1
read 80         
read 0L         # first offset
read 68
read 0
read [0x02]
read 0x4e8723aa
read 0s
read 0
read (long:timestamp)
read ${timestamp}
read -1L
read -1s
read -1
read 1
read ${kafka:varint(18)}
read [0x00]
read ${kafka:varint(0)}
read ${kafka:varint(0)}
read ${kafka:varint(-1)}
read ${kafka:varint(12)}
read "Hello, world"
read ${kafka:varint(0)}

# Fetch request results in an error
write 65
write 1s
write 5s
write ${newRequestId1}
write -1s
write -1
write ${maximumWaitTime}
write 1
write ${maximumBytes}
write [0x00]
write 1
write 4s "test"
write 1
write 0         # Partition
write 1L
write -1L
write ${maximumBytesTest0}

read 60
read ${newRequestId1}
read [0..4]
read 1          # Number of topic responses
read 4s "test"
read 1          # Number of partition responses
read 0          # Partition
read 6s         # error code NOT_LEADER_FOR_PARTITION
read 0L         # high watermark
read -1L
read 0L
read -1
read 0          # record set size

# Fetching continues when client re-subscribes
write 65
write 1s
write 5s
write ${newRequestId1}
write -1s
write -1
write ${maximumWaitTime}
write 1
write ${maximumBytes}
write [0x00]
write 1
write 4s "test"
write 1
write 0         # Partition
write 1L
write -1L
write ${maximumBytesTest0}  

# First historical fetch connection
connect await FETCH_CONNECTION_ONE_CONNECTED
        ${networkConnect}
  option nukleus:window ${networkConnectWindow}
  option nukleus:transmission "duplex"
  option nukleus:byteorder "network"
write nukleus:begin.ext ${tcp:beginExtRemoteHost("broker1", 9093)}
connected

read notify HISTORICAL_CONNECTION_ONE_CONNECTED

# Second fetch connection
connect await HISTORICAL_CONNECTION_ONE_CONNECTED
        ${networkConnect}
  option nukleus:window ${networkConnectWindow}
  option nukleus:transmission "duplex"
  option nukleus:byteorder "network"
write nukleus:begin.ext ${tcp:beginExtRemoteHost("broker2new", 9093)}
connected

read notify FETCH_CONNECTION_TWO_CONNECTED

write 65
write 1s
write 5s
write ${newRequestId1}
write -1s
write -1
write ${maximumWaitTime}
write 1
write ${maximumBytes}
write [0x00]
write 1
write 4s "test"
write 1
write 1         # Partition
write 0L
write -1L
write ${maximumBytesTest0}

read 140
read ${newRequestId1}
read [0..4]
read 1          # Number of topic responses
read 4s "test"
read 1          # Number of partition responses
read 1          # Partition
read 0s
read 1L         # high watermark
read -1L
read 0L
read -1
read 80         
read 0L         # first offset
read 68
read 0
read [0x02]
read 0x4e8723aa
read 0s
read 0
read (long:timestamp)
read ${timestamp}
read -1L
read -1s
read -1
read 1
read ${kafka:varint(18)}
read [0x00]
read ${kafka:varint(0)}
read ${kafka:varint(0)}
read ${kafka:varint(-1)}
read ${kafka:varint(12)}
read "Hello, again"
read ${kafka:varint(0)}

write 65
write 1s
write 5s
write ${newRequestId2}
write -1s
write -1
write ${maximumWaitTime}
write 1
write ${maximumBytes}
write [0x00]
write 1
write 4s "test"
write 1
write 1         # Partition
write 1L        # offset
write -1L
write ${maximumBytesTest0}

# Second historical fetch connection
connect await FETCH_CONNECTION_TWO_CONNECTED
        ${networkConnect}
  option nukleus:window ${networkConnectWindow}
  option nukleus:transmission "duplex"
  option nukleus:byteorder "network"
write nukleus:begin.ext ${tcp:beginExtRemoteHost("broker2new", 9093)}
connected
